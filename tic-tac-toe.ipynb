{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReadDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.genfromtxt('tic-tac-toe.data', delimiter=',', dtype='<U1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train&test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((958, 9), (958,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = arr[:, :9]\n",
    "y = arr[:, 9]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_rotate = []\n",
    "# X_flip_rotate = []\n",
    "\n",
    "# for i in range(4):\n",
    "#     X_matrix = X.reshape(-1, 3, 3)\n",
    "#     X_matrix_flip = np.fliplr(X_matrix)\n",
    "#     for i in range(X_matrix.shape[0]):\n",
    "\n",
    "#         x_rotate = np.rot90(X_matrix[i], i).reshape(-1, 9)\n",
    "#         X_rotate.append(x_rotate)\n",
    "        \n",
    "#         x_flip_rotate = np.rot90(X_matrix_flip[i], i).reshape(-1, 9)\n",
    "#         X_flip_rotate.append(x_flip_rotate)        \n",
    "    \n",
    "# a = np.array(X_rotate).reshape(-1, 9)\n",
    "# b = np.array(X_flip_rotate).reshape(-1, 9)\n",
    "# X = np.append(a, b, axis=0)\n",
    "\n",
    "# y = np.tile(y, 8)\n",
    "\n",
    "# X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Duplicate after rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((958, 9), (958,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, index = np.unique(X, axis=0, return_index=True)\n",
    "y = y[index]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((958, 9), (958, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = np.unique(X)\n",
    "inx = np.arange(feature.shape[0])\n",
    "search = np.searchsorted(feature, X)\n",
    "X = inx[search]\n",
    "\n",
    "uni = np.unique(y)\n",
    "inx = np.arange(uni.shape[0])\n",
    "search = np.searchsorted(uni, y)\n",
    "y = inx[search].reshape(-1, 1)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(958, 27)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_feature = feature.shape[0]\n",
    "one_hot = np.zeros((X.shape[0], X.shape[1], n_feature))\n",
    "for i, unique_value in enumerate(np.unique(X)):\n",
    "    one_hot[:, :, i][X == unique_value] = 1\n",
    "\n",
    "X = one_hot.reshape(-1, n_feature*X.shape[1])\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(958, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_feature = 2\n",
    "one_hot = np.zeros((y.shape[0], y.shape[1], n_feature))\n",
    "for i, unique_value in enumerate(np.unique(y)):\n",
    "    one_hot[:, :, i][y == unique_value] = 1\n",
    "\n",
    "y = one_hot.reshape(-1, n_feature*y.shape[1])\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_state = 0\n",
    "\n",
    "# np.random.seed(random_state)\n",
    "# np.random.shuffle(X)\n",
    "\n",
    "# np.random.seed(random_state)\n",
    "# np.random.shuffle(y)\n",
    "\n",
    "# X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "# sample = int(train_split*y.shape[0])\n",
    "\n",
    "# X_train, X_test = X[:sample], X[sample:]\n",
    "# y_train, y_test = y[:sample], y[sample:]\n",
    "\n",
    "# X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1 -train_size, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neurons=(729, 9), lr=0.06, decay=1e-6, momentum=0.9):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(neurons[0], activation='relu', input_shape=(X_train.shape[1:])))\n",
    "    model.add(Dense(neurons[1], activation='relu'))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "    optimizer = SGD(lr=lr, decay=decay, momentum=momentum, nesterov=True)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 729)               20412     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 6570      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 20        \n",
      "=================================================================\n",
      "Total params: 27,002\n",
      "Trainable params: 27,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 766 samples, validate on 192 samples\n",
      "Epoch 1/128\n",
      "766/766 [==============================] - 0s 188us/sample - loss: 0.5736 - acc: 0.6867 - val_loss: 0.5146 - val_acc: 0.7969\n",
      "Epoch 2/128\n",
      "766/766 [==============================] - 0s 66us/sample - loss: 0.4325 - acc: 0.8003 - val_loss: 0.3193 - val_acc: 0.8490\n",
      "Epoch 3/128\n",
      "766/766 [==============================] - 0s 73us/sample - loss: 0.2310 - acc: 0.9275 - val_loss: 0.1404 - val_acc: 0.9505\n",
      "Epoch 4/128\n",
      "766/766 [==============================] - 0s 67us/sample - loss: 0.0924 - acc: 0.9778 - val_loss: 0.0819 - val_acc: 0.9844\n",
      "Epoch 5/128\n",
      "766/766 [==============================] - 0s 67us/sample - loss: 0.1423 - acc: 0.9582 - val_loss: 0.0826 - val_acc: 0.9896\n",
      "Epoch 6/128\n",
      "766/766 [==============================] - 0s 66us/sample - loss: 0.0581 - acc: 0.9830 - val_loss: 0.0505 - val_acc: 0.9792\n",
      "Epoch 7/128\n",
      "766/766 [==============================] - 0s 72us/sample - loss: 0.0364 - acc: 0.9902 - val_loss: 0.0941 - val_acc: 0.9792\n",
      "Epoch 8/128\n",
      "766/766 [==============================] - 0s 66us/sample - loss: 0.0469 - acc: 0.9824 - val_loss: 0.0583 - val_acc: 0.9792\n",
      "Epoch 9/128\n",
      "766/766 [==============================] - 0s 66us/sample - loss: 0.0380 - acc: 0.9902 - val_loss: 0.1358 - val_acc: 0.9323\n",
      "Epoch 10/128\n",
      "766/766 [==============================] - 0s 70us/sample - loss: 0.0634 - acc: 0.9758 - val_loss: 0.0410 - val_acc: 0.9844\n",
      "Epoch 11/128\n",
      "766/766 [==============================] - 0s 65us/sample - loss: 0.0999 - acc: 0.9700 - val_loss: 0.0335 - val_acc: 0.9896\n",
      "Epoch 12/128\n",
      "766/766 [==============================] - 0s 69us/sample - loss: 0.0499 - acc: 0.9830 - val_loss: 0.0373 - val_acc: 0.9896\n",
      "Epoch 13/128\n",
      "766/766 [==============================] - 0s 66us/sample - loss: 0.0116 - acc: 0.9967 - val_loss: 0.0223 - val_acc: 0.9896\n",
      "Epoch 14/128\n",
      "766/766 [==============================] - 0s 66us/sample - loss: 0.0093 - acc: 0.9954 - val_loss: 0.0209 - val_acc: 0.9948\n",
      "Epoch 15/128\n",
      "766/766 [==============================] - 0s 66us/sample - loss: 0.0067 - acc: 0.9974 - val_loss: 0.0209 - val_acc: 0.9896\n",
      "Epoch 16/128\n",
      "766/766 [==============================] - 0s 72us/sample - loss: 0.0065 - acc: 0.9974 - val_loss: 0.0178 - val_acc: 0.9896\n",
      "Epoch 17/128\n",
      "766/766 [==============================] - 0s 67us/sample - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0163 - val_acc: 0.9896\n",
      "Epoch 18/128\n",
      "766/766 [==============================] - 0s 64us/sample - loss: 6.3224e-04 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 0.9844\n",
      "Epoch 19/128\n",
      "766/766 [==============================] - 0s 65us/sample - loss: 5.2009e-04 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9948\n",
      "Epoch 20/128\n",
      "766/766 [==============================] - 0s 70us/sample - loss: 4.1083e-04 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9948\n",
      "Epoch 21/128\n",
      "766/766 [==============================] - 0s 65us/sample - loss: 3.7905e-04 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 0.9948\n",
      "Epoch 22/128\n",
      "766/766 [==============================] - 0s 75us/sample - loss: 3.3176e-04 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 0.9948\n",
      "Epoch 23/128\n",
      "766/766 [==============================] - 0s 72us/sample - loss: 3.0390e-04 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 0.9948\n",
      "Epoch 24/128\n",
      "766/766 [==============================] - 0s 71us/sample - loss: 2.8046e-04 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 0.9948\n",
      "Epoch 25/128\n",
      "766/766 [==============================] - 0s 73us/sample - loss: 2.5972e-04 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 0.9948\n",
      "Epoch 26/128\n",
      "766/766 [==============================] - 0s 69us/sample - loss: 2.4514e-04 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 0.9948\n",
      "Epoch 27/128\n",
      "766/766 [==============================] - 0s 69us/sample - loss: 2.3231e-04 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 0.9948\n",
      "Epoch 28/128\n",
      "766/766 [==============================] - 0s 68us/sample - loss: 2.1856e-04 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 0.9948\n",
      "Epoch 29/128\n",
      "766/766 [==============================] - 0s 72us/sample - loss: 2.0361e-04 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 0.9948\n",
      "Epoch 30/128\n",
      "766/766 [==============================] - 0s 69us/sample - loss: 1.9555e-04 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 0.9948\n",
      "Epoch 31/128\n",
      "766/766 [==============================] - 0s 78us/sample - loss: 1.8699e-04 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 0.9948\n",
      "Epoch 32/128\n",
      "766/766 [==============================] - 0s 72us/sample - loss: 1.7977e-04 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9948\n",
      "Epoch 33/128\n",
      "766/766 [==============================] - 0s 75us/sample - loss: 1.7254e-04 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9948\n",
      "Epoch 34/128\n",
      "766/766 [==============================] - 0s 67us/sample - loss: 1.6496e-04 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9948\n",
      "Epoch 35/128\n",
      "766/766 [==============================] - 0s 68us/sample - loss: 1.5699e-04 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9948\n",
      "Epoch 36/128\n",
      "766/766 [==============================] - 0s 65us/sample - loss: 1.5367e-04 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9948\n",
      "Epoch 37/128\n",
      "766/766 [==============================] - 0s 68us/sample - loss: 1.4818e-04 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 0.9948\n",
      "Epoch 38/128\n",
      "766/766 [==============================] - 0s 71us/sample - loss: 1.4260e-04 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 0.9948\n",
      "Epoch 39/128\n",
      "766/766 [==============================] - 0s 71us/sample - loss: 1.3748e-04 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 0.9948\n",
      "Epoch 40/128\n",
      "766/766 [==============================] - 0s 70us/sample - loss: 1.3314e-04 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9948\n",
      "Epoch 41/128\n",
      "766/766 [==============================] - 0s 73us/sample - loss: 1.3137e-04 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 0.9948\n",
      "Epoch 42/128\n",
      "766/766 [==============================] - 0s 72us/sample - loss: 1.2631e-04 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9948\n",
      "Epoch 43/128\n",
      "766/766 [==============================] - 0s 72us/sample - loss: 1.2254e-04 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9948\n",
      "Epoch 44/128\n",
      "766/766 [==============================] - 0s 73us/sample - loss: 1.2043e-04 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 0.9948\n",
      "Epoch 45/128\n",
      "766/766 [==============================] - 0s 74us/sample - loss: 1.1567e-04 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 0.9948\n",
      "Epoch 46/128\n",
      "766/766 [==============================] - 0s 74us/sample - loss: 1.1292e-04 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 0.9948\n",
      "Epoch 47/128\n",
      "766/766 [==============================] - 0s 70us/sample - loss: 1.0963e-04 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 0.9948\n",
      "Epoch 48/128\n",
      "766/766 [==============================] - 0s 73us/sample - loss: 1.0741e-04 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 0.9948\n",
      "Epoch 49/128\n",
      "766/766 [==============================] - 0s 71us/sample - loss: 1.0503e-04 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 0.9948\n",
      "Epoch 50/128\n",
      "766/766 [==============================] - 0s 69us/sample - loss: 1.0178e-04 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9948\n",
      "Epoch 51/128\n",
      "766/766 [==============================] - 0s 72us/sample - loss: 1.0049e-04 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9948\n",
      "Epoch 52/128\n",
      "766/766 [==============================] - 0s 66us/sample - loss: 9.7471e-05 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 0.9948\n",
      "Epoch 53/128\n",
      "766/766 [==============================] - 0s 68us/sample - loss: 9.5716e-05 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9948\n",
      "Epoch 54/128\n",
      "766/766 [==============================] - 0s 76us/sample - loss: 9.3444e-05 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 0.9948\n",
      "Epoch 55/128\n",
      "766/766 [==============================] - 0s 69us/sample - loss: 9.1778e-05 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 0.9948\n",
      "Epoch 56/128\n",
      "766/766 [==============================] - 0s 68us/sample - loss: 8.9434e-05 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9948\n",
      "Epoch 57/128\n",
      "766/766 [==============================] - 0s 71us/sample - loss: 8.8274e-05 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 0.9948\n",
      "Epoch 58/128\n",
      "766/766 [==============================] - 0s 68us/sample - loss: 8.6956e-05 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 0.9974\n",
      "Epoch 59/128\n",
      "766/766 [==============================] - 0s 74us/sample - loss: 8.5512e-05 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9948\n",
      "Epoch 60/128\n",
      "766/766 [==============================] - 0s 65us/sample - loss: 8.3769e-05 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 0.9948\n",
      "Epoch 61/128\n",
      "766/766 [==============================] - 0s 76us/sample - loss: 8.1869e-05 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 0.9948\n",
      "Epoch 62/128\n",
      "766/766 [==============================] - 0s 70us/sample - loss: 8.0287e-05 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9948\n",
      "Epoch 63/128\n",
      "766/766 [==============================] - 0s 70us/sample - loss: 7.8653e-05 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9948\n",
      "Epoch 64/128\n",
      "766/766 [==============================] - 0s 72us/sample - loss: 7.7798e-05 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9948\n",
      "Epoch 65/128\n",
      "766/766 [==============================] - 0s 70us/sample - loss: 7.6306e-05 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9948\n",
      "Epoch 66/128\n",
      "766/766 [==============================] - 0s 64us/sample - loss: 7.5142e-05 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 0.9948\n",
      "Epoch 67/128\n",
      "766/766 [==============================] - 0s 69us/sample - loss: 7.3331e-05 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 0.9948\n",
      "Epoch 68/128\n",
      "766/766 [==============================] - 0s 73us/sample - loss: 7.3028e-05 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9948\n",
      "Epoch 69/128\n",
      "766/766 [==============================] - 0s 73us/sample - loss: 7.1326e-05 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9948\n",
      "Epoch 70/128\n",
      "766/766 [==============================] - 0s 71us/sample - loss: 7.0387e-05 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9948\n",
      "Epoch 71/128\n",
      "766/766 [==============================] - 0s 67us/sample - loss: 6.9144e-05 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9974\n",
      "Epoch 72/128\n",
      "766/766 [==============================] - 0s 66us/sample - loss: 6.8212e-05 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 0.9948\n",
      "Epoch 73/128\n",
      "766/766 [==============================] - 0s 69us/sample - loss: 6.6948e-05 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9948\n",
      "Epoch 74/128\n",
      "766/766 [==============================] - 0s 75us/sample - loss: 6.6090e-05 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9948\n",
      "Epoch 75/128\n",
      "766/766 [==============================] - 0s 69us/sample - loss: 6.5256e-05 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 0.9974\n",
      "Epoch 76/128\n",
      "766/766 [==============================] - 0s 71us/sample - loss: 6.4501e-05 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 0.9974\n",
      "Epoch 77/128\n",
      "766/766 [==============================] - 0s 67us/sample - loss: 6.3444e-05 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 0.9974\n",
      "Epoch 78/128\n",
      "766/766 [==============================] - 0s 77us/sample - loss: 6.2403e-05 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9974\n",
      "Epoch 79/128\n",
      "766/766 [==============================] - 0s 72us/sample - loss: 6.1476e-05 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 0.9974\n",
      "Epoch 80/128\n",
      "766/766 [==============================] - 0s 64us/sample - loss: 6.0931e-05 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9948\n",
      "Epoch 81/128\n",
      "766/766 [==============================] - 0s 71us/sample - loss: 5.9754e-05 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9974\n",
      "Epoch 82/128\n",
      "766/766 [==============================] - 0s 70us/sample - loss: 5.9593e-05 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9948\n",
      "Epoch 83/128\n",
      "766/766 [==============================] - 0s 73us/sample - loss: 5.8221e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 84/128\n",
      "766/766 [==============================] - 0s 69us/sample - loss: 5.7909e-05 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 85/128\n",
      "766/766 [==============================] - 0s 71us/sample - loss: 5.6788e-05 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9948\n",
      "Epoch 86/128\n",
      "766/766 [==============================] - 0s 72us/sample - loss: 5.6762e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 87/128\n",
      "766/766 [==============================] - 0s 71us/sample - loss: 5.5389e-05 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9948\n",
      "Epoch 88/128\n",
      "766/766 [==============================] - 0s 69us/sample - loss: 5.5009e-05 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 89/128\n",
      "766/766 [==============================] - 0s 73us/sample - loss: 5.4334e-05 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 0.9974\n",
      "Epoch 90/128\n",
      "766/766 [==============================] - 0s 72us/sample - loss: 5.3517e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 91/128\n",
      "766/766 [==============================] - 0s 73us/sample - loss: 5.3097e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 92/128\n",
      "766/766 [==============================] - 0s 65us/sample - loss: 5.2220e-05 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9974\n",
      "Epoch 93/128\n",
      "766/766 [==============================] - 0s 63us/sample - loss: 5.1842e-05 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 94/128\n",
      "766/766 [==============================] - 0s 68us/sample - loss: 5.1695e-05 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 95/128\n",
      "766/766 [==============================] - 0s 71us/sample - loss: 5.0568e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 96/128\n",
      "766/766 [==============================] - 0s 72us/sample - loss: 5.0427e-05 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 0.9974\n",
      "Epoch 97/128\n",
      "766/766 [==============================] - 0s 68us/sample - loss: 4.9617e-05 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 98/128\n",
      "766/766 [==============================] - 0s 71us/sample - loss: 4.9082e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 99/128\n",
      "766/766 [==============================] - 0s 73us/sample - loss: 4.8340e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 100/128\n",
      "766/766 [==============================] - 0s 72us/sample - loss: 4.7967e-05 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9974\n",
      "Epoch 101/128\n",
      "766/766 [==============================] - 0s 77us/sample - loss: 4.7217e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 102/128\n",
      "766/766 [==============================] - 0s 69us/sample - loss: 4.6808e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 103/128\n",
      "766/766 [==============================] - 0s 68us/sample - loss: 4.6529e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 104/128\n",
      "766/766 [==============================] - 0s 66us/sample - loss: 4.6391e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 105/128\n",
      "766/766 [==============================] - 0s 76us/sample - loss: 4.5531e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 106/128\n",
      "766/766 [==============================] - 0s 72us/sample - loss: 4.4930e-05 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 1.0000\n",
      "Epoch 107/128\n",
      "766/766 [==============================] - 0s 72us/sample - loss: 4.4518e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 108/128\n",
      "766/766 [==============================] - 0s 71us/sample - loss: 4.4063e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 109/128\n",
      "766/766 [==============================] - 0s 72us/sample - loss: 4.3716e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 110/128\n",
      "766/766 [==============================] - 0s 73us/sample - loss: 4.3193e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 111/128\n",
      "766/766 [==============================] - 0s 68us/sample - loss: 4.2914e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 112/128\n",
      "766/766 [==============================] - 0s 71us/sample - loss: 4.2375e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 113/128\n",
      "766/766 [==============================] - 0s 70us/sample - loss: 4.2113e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 114/128\n",
      "766/766 [==============================] - 0s 75us/sample - loss: 4.1709e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 115/128\n",
      "766/766 [==============================] - 0s 70us/sample - loss: 4.1327e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 116/128\n",
      "766/766 [==============================] - 0s 69us/sample - loss: 4.0947e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 117/128\n",
      "766/766 [==============================] - 0s 75us/sample - loss: 4.0488e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 118/128\n",
      "766/766 [==============================] - 0s 68us/sample - loss: 4.0179e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 119/128\n",
      "766/766 [==============================] - 0s 65us/sample - loss: 3.9986e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 120/128\n",
      "766/766 [==============================] - 0s 67us/sample - loss: 3.9345e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 121/128\n",
      "766/766 [==============================] - 0s 71us/sample - loss: 3.9030e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 122/128\n",
      "766/766 [==============================] - 0s 67us/sample - loss: 3.8586e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 123/128\n",
      "766/766 [==============================] - 0s 70us/sample - loss: 3.8443e-05 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 124/128\n",
      "766/766 [==============================] - 0s 68us/sample - loss: 3.7925e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 125/128\n",
      "766/766 [==============================] - 0s 70us/sample - loss: 3.7747e-05 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
      "Epoch 126/128\n",
      "766/766 [==============================] - 0s 71us/sample - loss: 3.7377e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 127/128\n",
      "766/766 [==============================] - 0s 70us/sample - loss: 3.7020e-05 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 128/128\n",
      "766/766 [==============================] - 0s 67us/sample - loss: 3.6919e-05 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "epochs = 128\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training accuracy and Training Loss Graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Training loss')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2, sharex=True)\n",
    "\n",
    "ax[0].plot(history.history['acc'], label=model)\n",
    "ax[1].plot(history.history['loss'], label=model)\n",
    " \n",
    "ax[0].set_xlabel('epochs')\n",
    "ax[0].set_ylabel('Training accuracy')\n",
    "ax[1].set_ylabel('Training loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 0s 17us/sample - loss: 0.0083 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 67,   0],\n",
       "       [  0, 125]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_argmax = y_test.argmax(axis=1)\n",
    "y_pred = model.predict_classes(X_test)\n",
    "confusion_matrix(y_test_argmax, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covent_to_matrix(index):\n",
    "    aaa = X_test[index].reshape(-1, 3).argmax(axis=1).astype('U1')\n",
    "    for j, unique_value in enumerate(feature):\n",
    "        aaa[aaa==str(j)] = unique_value\n",
    "\n",
    "    return aaa.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_failed_index = np.where(y_test_argmax != y_pred)[0]\n",
    "for i in x_failed_index:\n",
    "    print(f'index {i}, y_test {y_test_argmax[i]}, y_pred {y_pred[i]}')\n",
    "    print(covent_to_matrix(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receiver Operating Characteristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f22e01784e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test_argmax,  y_pred)\n",
    "auc = roc_auc_score(y_test_argmax, y_pred)\n",
    "\n",
    "plt.plot(fpr, tpr, marker='.', label=f'AUC: {auc}')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'neurons' : [(16, 16), (32, 32)],\n",
    "    'lr' : [0.01, 0.1],\n",
    "    'momentum' : [0.8, 0.9],\n",
    "    'batch_size' : [8, 16],\n",
    "    'epochs' : [40, 60],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "# grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# print('best score: ', grid_result.best_score_, grid_result.best_params_)\n",
    "\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(f'{mean} ({stdev}) with: {param}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average test accuracy rate in 12 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - loss: 2.3894212217521993e-05 - acc: 1.0\n",
      "192/192 [==============================] - 0s 101us/sample - loss: 0.0128 - acc: 0.9948\n",
      "index failed: [101]\n",
      "index 101, y_test 1, y_pred 0\n",
      "[['x' 'x' 'o']\n",
      " ['x' 'o' 'o']\n",
      " ['x' 'o' 'x']]\n",
      "Train - loss: 2.529843993700194e-05 - acc: 1.0\n",
      "192/192 [==============================] - 0s 111us/sample - loss: 0.0106 - acc: 0.9948\n",
      "index failed: [101]\n",
      "index 101, y_test 1, y_pred 0\n",
      "[['x' 'x' 'o']\n",
      " ['x' 'o' 'o']\n",
      " ['x' 'o' 'x']]\n",
      "Train - loss: 3.577303577817985e-05 - acc: 1.0\n",
      "192/192 [==============================] - 0s 123us/sample - loss: 0.0126 - acc: 0.9922\n",
      "index failed: [62]\n",
      "index 62, y_test 0, y_pred 1\n",
      "[['o' 'x' 'x']\n",
      " ['x' 'o' 'o']\n",
      " ['o' 'x' 'x']]\n",
      "Train - loss: 3.2445231647344365e-05 - acc: 1.0\n",
      "192/192 [==============================] - 0s 141us/sample - loss: 0.0063 - acc: 1.0000\n",
      "index failed: []\n",
      "Train - loss: 2.406731722748388e-05 - acc: 1.0\n",
      "192/192 [==============================] - 0s 153us/sample - loss: 0.0103 - acc: 0.9948\n",
      "index failed: [101]\n",
      "index 101, y_test 1, y_pred 0\n",
      "[['x' 'x' 'o']\n",
      " ['x' 'o' 'o']\n",
      " ['x' 'o' 'x']]\n",
      "Train - loss: 3.617285613664979e-05 - acc: 1.0\n",
      "192/192 [==============================] - 0s 166us/sample - loss: 0.0109 - acc: 0.9948\n",
      "index failed: [188]\n",
      "index 188, y_test 0, y_pred 1\n",
      "[['x' 'o' 'x']\n",
      " ['o' 'o' 'x']\n",
      " ['x' 'x' 'o']]\n",
      "Train - loss: 4.048239007447556e-05 - acc: 1.0\n",
      "192/192 [==============================] - 0s 187us/sample - loss: 0.0153 - acc: 0.9948\n",
      "index failed: [62]\n",
      "index 62, y_test 0, y_pred 1\n",
      "[['o' 'x' 'x']\n",
      " ['x' 'o' 'o']\n",
      " ['o' 'x' 'x']]\n",
      "Train - loss: 3.850710078045469e-05 - acc: 1.0\n",
      "192/192 [==============================] - 0s 209us/sample - loss: 0.0103 - acc: 0.9974\n",
      "index failed: [101]\n",
      "index 101, y_test 1, y_pred 0\n",
      "[['x' 'x' 'o']\n",
      " ['x' 'o' 'o']\n",
      " ['x' 'o' 'x']]\n",
      "Train - loss: 2.8930666168139338e-05 - acc: 1.0\n",
      "192/192 [==============================] - 0s 228us/sample - loss: 0.0068 - acc: 1.0000\n",
      "index failed: []\n",
      "Train - loss: 3.955943743593358e-05 - acc: 1.0\n",
      "192/192 [==============================] - 0s 294us/sample - loss: 0.0062 - acc: 1.0000\n",
      "index failed: []\n",
      "Train - loss: 2.772291602213337e-05 - acc: 1.0\n",
      "192/192 [==============================] - 0s 268us/sample - loss: 0.0041 - acc: 1.0000\n",
      "index failed: []\n",
      "Train - loss: 3.441933878941304e-05 - acc: 1.0\n",
      "192/192 [==============================] - 0s 318us/sample - loss: 0.0054 - acc: 1.0000\n",
      "index failed: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Max accuracy rate :',\n",
       " 1.0,\n",
       " 'Avg accuracy rate :',\n",
       " 0.99696183,\n",
       " 'Min accuracy rate :',\n",
       " 0.9921875)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for i in range(12):\n",
    "    model = create_model()\n",
    "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "    print(f'Train - loss: {history.history[\"loss\"][-1]} - acc: {history.history[\"acc\"][-1]}')\n",
    "\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    scores.append(score[1])\n",
    "          \n",
    "    y_pred = model.predict_classes(X_test)\n",
    "    x_failed_index = np.where(y_test_argmax != y_pred)[0]\n",
    "          \n",
    "    print('index failed:', x_failed_index)\n",
    "    for i in x_failed_index:\n",
    "        print(f'index {i}, y_test {y_test_argmax[i]}, y_pred {y_pred[i]}')\n",
    "        print(covent_to_matrix(i))\n",
    "          \n",
    "scores = np.array(scores)\n",
    "'Max accuracy rate :', scores.max(), 'Avg accuracy rate :', np.average(scores), 'Min accuracy rate :', scores.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
