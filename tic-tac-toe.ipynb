{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReadDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.genfromtxt('tic-tac-toe.data', delimiter=',', dtype='<U1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((958, 9), (958,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state = 0\n",
    "\n",
    "np.random.seed(random_state)\n",
    "np.random.shuffle(arr)\n",
    "\n",
    "X = arr[:, :9]\n",
    "y = arr[:, 9]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((958, 9), (958, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = np.unique(X)\n",
    "inx = np.arange(feature.shape[0])\n",
    "search = np.searchsorted(feature, X)\n",
    "X = inx[search]\n",
    "\n",
    "uni = np.unique(y)\n",
    "inx = np.arange(uni.shape[0])\n",
    "search = np.searchsorted(uni, y)\n",
    "y = inx[search].reshape(-1, 1)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(958, 27)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_feature = feature.shape[0]\n",
    "one_hot = np.zeros((X.shape[0], X.shape[1], n_feature))\n",
    "for i, unique_value in enumerate(np.unique(X)):\n",
    "    one_hot[:, :, i][X == unique_value] = 1\n",
    "\n",
    "X = one_hot.reshape(-1, n_feature*X.shape[1])\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((670, 27), (288, 27))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split = 0.7\n",
    "sample = int(train_split*arr.shape[0])\n",
    "\n",
    "X_train, X_test = X[:sample], X[sample:]\n",
    "y_train, y_test = y[:sample], y[sample:]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 224       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 385\n",
      "Trainable params: 385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(8, activation='relu', input_shape=(X_train.shape[1:])))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 670 samples, validate on 288 samples\n",
      "Epoch 1/50\n",
      "670/670 [==============================] - 0s 201us/sample - loss: 0.6549 - acc: 0.6493 - val_loss: 0.6416 - val_acc: 0.6632\n",
      "Epoch 2/50\n",
      "670/670 [==============================] - 0s 73us/sample - loss: 0.6416 - acc: 0.6493 - val_loss: 0.6276 - val_acc: 0.6632\n",
      "Epoch 3/50\n",
      "670/670 [==============================] - 0s 68us/sample - loss: 0.6309 - acc: 0.6493 - val_loss: 0.6161 - val_acc: 0.6701\n",
      "Epoch 4/50\n",
      "670/670 [==============================] - 0s 71us/sample - loss: 0.6199 - acc: 0.6507 - val_loss: 0.6012 - val_acc: 0.6771\n",
      "Epoch 5/50\n",
      "670/670 [==============================] - 0s 65us/sample - loss: 0.6049 - acc: 0.6731 - val_loss: 0.5890 - val_acc: 0.6875\n",
      "Epoch 6/50\n",
      "670/670 [==============================] - 0s 70us/sample - loss: 0.5905 - acc: 0.6970 - val_loss: 0.5751 - val_acc: 0.7049\n",
      "Epoch 7/50\n",
      "670/670 [==============================] - 0s 63us/sample - loss: 0.5725 - acc: 0.7284 - val_loss: 0.5625 - val_acc: 0.7292\n",
      "Epoch 8/50\n",
      "670/670 [==============================] - 0s 67us/sample - loss: 0.5538 - acc: 0.7418 - val_loss: 0.5500 - val_acc: 0.7257\n",
      "Epoch 9/50\n",
      "670/670 [==============================] - 0s 64us/sample - loss: 0.5370 - acc: 0.7493 - val_loss: 0.5395 - val_acc: 0.7292\n",
      "Epoch 10/50\n",
      "670/670 [==============================] - 0s 62us/sample - loss: 0.5202 - acc: 0.7507 - val_loss: 0.5320 - val_acc: 0.7292\n",
      "Epoch 11/50\n",
      "670/670 [==============================] - 0s 60us/sample - loss: 0.5062 - acc: 0.7507 - val_loss: 0.5237 - val_acc: 0.7292\n",
      "Epoch 12/50\n",
      "670/670 [==============================] - 0s 64us/sample - loss: 0.4923 - acc: 0.7627 - val_loss: 0.5167 - val_acc: 0.7361\n",
      "Epoch 13/50\n",
      "670/670 [==============================] - 0s 62us/sample - loss: 0.4805 - acc: 0.7597 - val_loss: 0.5088 - val_acc: 0.7465\n",
      "Epoch 14/50\n",
      "670/670 [==============================] - 0s 67us/sample - loss: 0.4677 - acc: 0.7627 - val_loss: 0.5019 - val_acc: 0.7465\n",
      "Epoch 15/50\n",
      "670/670 [==============================] - 0s 68us/sample - loss: 0.4560 - acc: 0.7731 - val_loss: 0.4952 - val_acc: 0.7431\n",
      "Epoch 16/50\n",
      "670/670 [==============================] - 0s 59us/sample - loss: 0.4452 - acc: 0.7776 - val_loss: 0.4905 - val_acc: 0.7396\n",
      "Epoch 17/50\n",
      "670/670 [==============================] - 0s 70us/sample - loss: 0.4331 - acc: 0.7910 - val_loss: 0.4800 - val_acc: 0.7465\n",
      "Epoch 18/50\n",
      "670/670 [==============================] - 0s 62us/sample - loss: 0.4235 - acc: 0.7851 - val_loss: 0.4720 - val_acc: 0.7465\n",
      "Epoch 19/50\n",
      "670/670 [==============================] - 0s 63us/sample - loss: 0.4112 - acc: 0.7940 - val_loss: 0.4657 - val_acc: 0.7604\n",
      "Epoch 20/50\n",
      "670/670 [==============================] - 0s 70us/sample - loss: 0.4017 - acc: 0.8104 - val_loss: 0.4582 - val_acc: 0.7743\n",
      "Epoch 21/50\n",
      "670/670 [==============================] - 0s 60us/sample - loss: 0.3864 - acc: 0.8179 - val_loss: 0.4454 - val_acc: 0.7639\n",
      "Epoch 22/50\n",
      "670/670 [==============================] - 0s 62us/sample - loss: 0.3736 - acc: 0.8313 - val_loss: 0.4378 - val_acc: 0.7882\n",
      "Epoch 23/50\n",
      "670/670 [==============================] - 0s 59us/sample - loss: 0.3605 - acc: 0.8403 - val_loss: 0.4231 - val_acc: 0.7986\n",
      "Epoch 24/50\n",
      "670/670 [==============================] - 0s 60us/sample - loss: 0.3475 - acc: 0.8463 - val_loss: 0.4130 - val_acc: 0.7917\n",
      "Epoch 25/50\n",
      "670/670 [==============================] - 0s 59us/sample - loss: 0.3352 - acc: 0.8552 - val_loss: 0.4008 - val_acc: 0.8056\n",
      "Epoch 26/50\n",
      "670/670 [==============================] - 0s 60us/sample - loss: 0.3194 - acc: 0.8672 - val_loss: 0.3870 - val_acc: 0.8125\n",
      "Epoch 27/50\n",
      "670/670 [==============================] - 0s 71us/sample - loss: 0.3047 - acc: 0.8821 - val_loss: 0.3766 - val_acc: 0.8160\n",
      "Epoch 28/50\n",
      "670/670 [==============================] - 0s 63us/sample - loss: 0.2916 - acc: 0.8836 - val_loss: 0.3621 - val_acc: 0.8194\n",
      "Epoch 29/50\n",
      "670/670 [==============================] - 0s 61us/sample - loss: 0.2778 - acc: 0.9000 - val_loss: 0.3478 - val_acc: 0.8229\n",
      "Epoch 30/50\n",
      "670/670 [==============================] - 0s 60us/sample - loss: 0.2642 - acc: 0.9015 - val_loss: 0.3328 - val_acc: 0.8403\n",
      "Epoch 31/50\n",
      "670/670 [==============================] - 0s 63us/sample - loss: 0.2500 - acc: 0.9164 - val_loss: 0.3231 - val_acc: 0.8472\n",
      "Epoch 32/50\n",
      "670/670 [==============================] - 0s 60us/sample - loss: 0.2408 - acc: 0.9104 - val_loss: 0.3070 - val_acc: 0.8611\n",
      "Epoch 33/50\n",
      "670/670 [==============================] - 0s 60us/sample - loss: 0.2238 - acc: 0.9209 - val_loss: 0.2911 - val_acc: 0.8681\n",
      "Epoch 34/50\n",
      "670/670 [==============================] - 0s 60us/sample - loss: 0.2120 - acc: 0.9343 - val_loss: 0.2768 - val_acc: 0.8785\n",
      "Epoch 35/50\n",
      "670/670 [==============================] - 0s 59us/sample - loss: 0.1992 - acc: 0.9418 - val_loss: 0.2668 - val_acc: 0.8819\n",
      "Epoch 36/50\n",
      "670/670 [==============================] - 0s 59us/sample - loss: 0.1872 - acc: 0.9448 - val_loss: 0.2498 - val_acc: 0.8958\n",
      "Epoch 37/50\n",
      "670/670 [==============================] - 0s 60us/sample - loss: 0.1777 - acc: 0.9493 - val_loss: 0.2454 - val_acc: 0.8924\n",
      "Epoch 38/50\n",
      "670/670 [==============================] - 0s 59us/sample - loss: 0.1645 - acc: 0.9612 - val_loss: 0.2215 - val_acc: 0.9028\n",
      "Epoch 39/50\n",
      "670/670 [==============================] - 0s 59us/sample - loss: 0.1531 - acc: 0.9627 - val_loss: 0.2077 - val_acc: 0.9097\n",
      "Epoch 40/50\n",
      "670/670 [==============================] - 0s 59us/sample - loss: 0.1424 - acc: 0.9642 - val_loss: 0.1985 - val_acc: 0.9132\n",
      "Epoch 41/50\n",
      "670/670 [==============================] - 0s 59us/sample - loss: 0.1341 - acc: 0.9687 - val_loss: 0.1803 - val_acc: 0.9236\n",
      "Epoch 42/50\n",
      "670/670 [==============================] - 0s 59us/sample - loss: 0.1245 - acc: 0.9716 - val_loss: 0.1718 - val_acc: 0.9271\n",
      "Epoch 43/50\n",
      "670/670 [==============================] - 0s 60us/sample - loss: 0.1155 - acc: 0.9746 - val_loss: 0.1686 - val_acc: 0.9271\n",
      "Epoch 44/50\n",
      "670/670 [==============================] - 0s 59us/sample - loss: 0.1086 - acc: 0.9776 - val_loss: 0.1490 - val_acc: 0.9340\n",
      "Epoch 45/50\n",
      "670/670 [==============================] - 0s 59us/sample - loss: 0.1044 - acc: 0.9761 - val_loss: 0.1405 - val_acc: 0.9375\n",
      "Epoch 46/50\n",
      "670/670 [==============================] - 0s 59us/sample - loss: 0.0963 - acc: 0.9806 - val_loss: 0.1340 - val_acc: 0.9340\n",
      "Epoch 47/50\n",
      "670/670 [==============================] - 0s 59us/sample - loss: 0.0907 - acc: 0.9791 - val_loss: 0.1236 - val_acc: 0.9514\n",
      "Epoch 48/50\n",
      "670/670 [==============================] - 0s 59us/sample - loss: 0.0841 - acc: 0.9881 - val_loss: 0.1217 - val_acc: 0.9653\n",
      "Epoch 49/50\n",
      "670/670 [==============================] - 0s 59us/sample - loss: 0.0806 - acc: 0.9821 - val_loss: 0.1101 - val_acc: 0.9722\n",
      "Epoch 50/50\n",
      "670/670 [==============================] - 0s 59us/sample - loss: 0.0748 - acc: 0.9836 - val_loss: 0.1081 - val_acc: 0.9653\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "epochs = 50\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
